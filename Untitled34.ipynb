{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      a\n",
      "0      7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6\n",
      "1     6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9...\n",
      "2     8.1;0.28;0.4;6.9;0.05;30;97;0.9951;3.26;0.44;1...\n",
      "3     7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...\n",
      "4     7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...\n",
      "...                                                 ...\n",
      "4893  6.2;0.21;0.29;1.6;0.039;24;92;0.99114;3.27;0.5...\n",
      "4894  6.6;0.32;0.36;8;0.047;57;168;0.9949;3.15;0.46;...\n",
      "4895  6.5;0.24;0.19;1.2;0.041;30;111;0.99254;2.99;0....\n",
      "4896  5.5;0.29;0.3;1.1;0.022;20;110;0.98869;3.34;0.3...\n",
      "4897  6;0.21;0.38;0.8;0.02;22;98;0.98941;3.26;0.32;1...\n",
      "\n",
      "[4898 rows x 1 columns]\n",
      "       0     1     2     3      4   5    6        7     8     9     10 11\n",
      "0       7  0.27  0.36  20.7  0.045  45  170    1.001     3  0.45   8.8  6\n",
      "1     6.3   0.3  0.34   1.6  0.049  14  132    0.994   3.3  0.49   9.5  6\n",
      "2     8.1  0.28   0.4   6.9   0.05  30   97   0.9951  3.26  0.44  10.1  6\n",
      "3     7.2  0.23  0.32   8.5  0.058  47  186   0.9956  3.19   0.4   9.9  6\n",
      "4     7.2  0.23  0.32   8.5  0.058  47  186   0.9956  3.19   0.4   9.9  6\n",
      "...   ...   ...   ...   ...    ...  ..  ...      ...   ...   ...   ... ..\n",
      "4893  6.2  0.21  0.29   1.6  0.039  24   92  0.99114  3.27   0.5  11.2  6\n",
      "4894  6.6  0.32  0.36     8  0.047  57  168   0.9949  3.15  0.46   9.6  5\n",
      "4895  6.5  0.24  0.19   1.2  0.041  30  111  0.99254  2.99  0.46   9.4  6\n",
      "4896  5.5  0.29   0.3   1.1  0.022  20  110  0.98869  3.34  0.38  12.8  7\n",
      "4897    6  0.21  0.38   0.8   0.02  22   98  0.98941  3.26  0.32  11.8  6\n",
      "\n",
      "[4898 rows x 12 columns]\n",
      "Training data\n",
      "\n",
      "       0     1     2     3      4   5    6        7     8     9     10 11\n",
      "0       7  0.27  0.36  20.7  0.045  45  170    1.001     3  0.45   8.8  6\n",
      "1     6.3   0.3  0.34   1.6  0.049  14  132    0.994   3.3  0.49   9.5  6\n",
      "2     8.1  0.28   0.4   6.9   0.05  30   97   0.9951  3.26  0.44  10.1  6\n",
      "3     7.2  0.23  0.32   8.5  0.058  47  186   0.9956  3.19   0.4   9.9  6\n",
      "4     7.2  0.23  0.32   8.5  0.058  47  186   0.9956  3.19   0.4   9.9  6\n",
      "...   ...   ...   ...   ...    ...  ..  ...      ...   ...   ...   ... ..\n",
      "4892  6.5  0.23  0.38   1.3  0.032  29  112  0.99298  3.29  0.54   9.7  5\n",
      "4894  6.6  0.32  0.36     8  0.047  57  168   0.9949  3.15  0.46   9.6  5\n",
      "4895  6.5  0.24  0.19   1.2  0.041  30  111  0.99254  2.99  0.46   9.4  6\n",
      "4896  5.5  0.29   0.3   1.1  0.022  20  110  0.98869  3.34  0.38  12.8  7\n",
      "4897    6  0.21  0.38   0.8   0.02  22   98  0.98941  3.26  0.32  11.8  6\n",
      "\n",
      "[4408 rows x 12 columns]\n",
      "\n",
      " Test data\n",
      "\n",
      "       0     1     2      3      4   5    6        7     8     9     10 11\n",
      "15    6.6  0.17  0.38    1.5  0.032  28  112   0.9914  3.25  0.55  11.4  7\n",
      "21    6.4  0.31  0.38    2.9  0.038  19  102   0.9912  3.17  0.35    11  7\n",
      "22    6.8  0.26  0.42    1.7  0.049  41  122    0.993  3.47  0.48  10.5  8\n",
      "33    6.2  0.12  0.34    1.5  0.045  43  117   0.9939  3.42  0.51     9  6\n",
      "34    5.8  0.27   0.2  14.95  0.044  22  179   0.9962  3.37  0.37  10.2  5\n",
      "...   ...   ...   ...    ...    ...  ..  ...      ...   ...   ...   ... ..\n",
      "4843  5.6  0.34  0.25    2.5  0.046  47  182  0.99093  3.21   0.4  11.3  5\n",
      "4849  6.4  0.33  0.44    8.9  0.055  52  164  0.99488   3.1  0.48   9.6  5\n",
      "4851  6.4  0.33  0.44    8.9  0.055  52  164  0.99488   3.1  0.48   9.6  5\n",
      "4866  5.7  0.41  0.21    1.9  0.048  30  112  0.99138  3.29  0.55  11.2  6\n",
      "4893  6.2  0.21  0.29    1.6  0.039  24   92  0.99114  3.27   0.5  11.2  6\n",
      "\n",
      "[490 rows x 12 columns]\n",
      "\n",
      "Decision tree Result\n",
      " {\n",
      "    \"11\": {\n",
      "        \"3\": \"3\",\n",
      "        \"4\": \"4\",\n",
      "        \"5\": \"5\",\n",
      "        \"6\": \"6\",\n",
      "        \"7\": \"7\",\n",
      "        \"8\": \"8\",\n",
      "        \"9\": \"9\"\n",
      "    }\n",
      "}\n",
      "Column is  11\n",
      "Attribute:  7 \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-14e6715e3fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mcolumn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m#except we serached once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Column is \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "data=pd.read_csv(\"C:\\winequality-white.csv\",dtype=\"string_\",sep=';')\n",
    "count_column=int(len(data)*(9/10))\n",
    "\n",
    "# splitRandom function\n",
    "# description : split data randomly \n",
    "def splitRandom(origin):\n",
    "    list_all=np.arange(len(origin)).tolist()\n",
    "    #randomly select amount of count in 0~ length of data(index of training) \n",
    "    list_training= random.sample(list_all, count_column)\n",
    "    \n",
    "    list_testing=[]#array store index of testing\n",
    "\n",
    "    #test, training index are not duplicate\n",
    "\n",
    "    for i in range(len(list_all)):\n",
    "        for j in range(len(list_training)):\n",
    "            if i==list_training[j]:\n",
    "                break;\n",
    "            else:\n",
    "                if j==len(list_training)-1:\n",
    "                    list_testing.append(i)\n",
    "                \n",
    "    \n",
    "     #split data train, test using index\n",
    "    data_training=origin.drop(list_testing)\n",
    "    data_testing=origin.drop(list_training);\n",
    "\n",
    "    return data_training, data_testing\n",
    "#ID3 function\n",
    "#make decision tree\n",
    "def ID3(data, originaldata, features, target, parent_node_class=None):\n",
    "    \n",
    "\n",
    "    #Unique value of target data, number of each.\n",
    "    elements, count=np.unique(data[target],return_counts=True)\n",
    "   \n",
    "  \n",
    "    #attribute has single value (==child node is label data)\n",
    "    if len(count)<=1:\n",
    "       \n",
    "        return elements[0]\n",
    "   \n",
    "    elif len(features)==0:\n",
    "        return parent_node_class\n",
    "    #bulid tree\n",
    "    else:\n",
    "\n",
    "        #select parent node\n",
    "        parent_node_class=elements[np.argmax(count)]\n",
    "\n",
    "        #store information gain of each attributes\n",
    "        item_values=[]\n",
    "\n",
    "        #print parent node entropy\n",
    "      \n",
    "\n",
    "        # store inforamtion gain of each features in itme_values\n",
    "        for i in features:\n",
    "            item_values.append(informationGain(data,i,target))\n",
    "            \n",
    "            \n",
    "\n",
    "        #select the feature which is the biggest inforamation gain \n",
    "        index=np.argmax(item_values)\n",
    "        select=features[index]\n",
    "\n",
    "        \n",
    "        #create tree structre\n",
    "        tree={select:{}}\n",
    "\n",
    "        #features store features except selected feature\n",
    "        features=[i for i in features if i!=select]\n",
    "    \n",
    "        #draw child node of selected feature\n",
    "        for value in np.unique(data[select]):\n",
    "            sub_data=data.where(data[select]==value).dropna() #sub_data is data of selected features same with value\n",
    "          \n",
    "            subtree=ID3(sub_data, data, features, target, parent_node_class)#draw tree only using selected features\n",
    "            tree[select][value]=subtree #store tree result\n",
    "        return(tree)\n",
    "def informationGain(data,column,target):\n",
    "    entropy_total=entropy(data[target]) #calculate parent(root) entropy\n",
    "    elements,counts=np.unique(data[column],return_counts=True) # elements is unique value , count is number of each value\n",
    "\n",
    "    entropy_w=0 #entropy_w is weight entropy\n",
    "    for i in range(len(elements)):\n",
    "        en=entropy(data.where(data[column]==elements[i]).dropna()[target])#calculate entropy of each features\n",
    "       \n",
    "        entropy_w=entropy_w+counts[i]*en\n",
    "        \n",
    "    #calculate average\n",
    "    entropy_w=entropy_w/np.sum(counts)\n",
    "    \n",
    "\n",
    "    #calcualte information gain and return it\n",
    "    return entropy_total-entropy_w\n",
    "def entropy(data):\n",
    "    elements,count=np.unique(data,return_counts=True)# elements is unique value , count is number of each value\n",
    "\n",
    "    #if number of unqiue target value(labeld value) -> entropy is 0\n",
    "    if len(count)==1:\n",
    "        en=0\n",
    "        \n",
    "    # else calculate entropy\n",
    "    else:\n",
    "        p1=count[0]/np.sum(count)\n",
    "        p2=count[1]/np.sum(count)\n",
    "        en=-(p1*np.log2(p1)+p2*np.log2(p2))\n",
    "    return en\n",
    "print(data)\n",
    "#split data to train, test using splitRandom function    \n",
    "\n",
    "train,test=splitRandom(split)\n",
    "\n",
    "\n",
    "#print trian, test data\n",
    "print(\"Training data\\n\")\n",
    "print(train)\n",
    "print(\"\\n Test data\\n\")\n",
    "print(test)\n",
    "\n",
    "#features is the all feautres in data\n",
    "features=[0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "target=[11] #labeld data\n",
    "result=ID3(train,train,features, target) #call ID3 function result is decision tree\n",
    "print(\"\\nDecision tree Result\\n\",json.dumps(result, indent=4))\n",
    "\n",
    "#list for predict data\n",
    "predict=[]\n",
    "\n",
    "org=result.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
